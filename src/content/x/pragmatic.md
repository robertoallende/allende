---
title: "Pragmatic GenAI"
description: "How to use GenAI deliberately, with control, iteration, and responsibility"
section: "genai"
---

## What GenAI Is (and Is Not)

GenAI, used pragmatically, is a **reasoning and iteration tool**—not an authority and not an autonomous actor. It accelerates how humans **think, explore, structure, and refine ideas**, while judgment, responsibility, and final decisions remain unequivocally human.

Tool-augmented models (for example, those with live web search, such as Perplexity) make oracle-style interactions possible, but not reliable. Retrieved information can be incomplete, misinterpreted, or incorrectly synthesized. As a result, GenAI should still be used primarily to generate candidates, not to deliver authoritative answers.

The human evaluates those candidates, rejects weak ones, refines promising ones, and iterates.  

The leverage comes from the **feedback loop**, not from correctness.

## How This Shows Up in Practice

GenAI acts as a **cognitive workbench**. Humans use conversation as a way of thinking: by holding a dialog with a large body of knowledge, ideas can be explored from multiple angles, challenged, and refined in language. Instead of holding complex problems in your head—leadership challenges, accountability gaps, policy framing, modernization strategy—you push rough thinking into words, inspect it, reshape it, and progressively sharpen it.

It **compresses learning cycles**. Asking for definitions, authors, competing models, or mental frameworks is not oracle-style querying; it is rapid landscape mapping. The goal is not to accept answers, but to orient yourself quickly so you can reason better, ask better questions, and make informed trade-offs—especially in unfamiliar domains.

It helps create **legible artefacts**. Documents, outlines, narratives, emails, policies, talk proposals, and strategy notes are not content for its own sake. They stabilize thinking over time, reduce drift, and turn vague concerns into inspectable objects that can be revisited and improved.

It allows you to **move faster without losing control**. By being explicit about scope, constraints, and iteration, you avoid the confusion that unconstrained GenAI amplifies. Work is broken into reviewable chunks, single-responsibility thinking is applied, and progress is gated through human judgment.

Most importantly, GenAI is used to **amplify intent, not replace agency**. The model proposes; the human decides. The model accelerates; the human remains accountable.

## A Pragmatic Definition

> GenAI is a human-language interface to a large body of knowledge that enables rapid exploration and iteration.  
> It produces candidate ideas and structures, which a human evaluates, constrains, and refines.  
> Value emerges from the feedback loop, not from treating the system as an authority.

This is why **AI isn’t the differentiator—judgment is**.  

GenAI multiplies whatever operating discipline already exists. Used deliberately, it sharpens thinking, shortens learning loops, and improves decision quality. Used carelessly, it accelerates confusion.

---

## Example: How to Use GenAI to Write an Article

### The Core Philosophy

Interacting with an LLM is less about asking isolated questions and more about shaping a **feedback loop**. The model generates candidate interpretations, structures, or explanations, and the human evaluates and steers them. Progress emerges through iteration rather than authority, with responsibility and judgment remaining with the human throughout.

For example, asking *“What time is it?”* is an oracle-style interaction: a single question expecting a single correct answer.

In contrast, asking whether the model is familiar with a concept—such as the definition of strategy, the main authors, and the core ideas—and then using those elements to iteratively shape an article for a specific audience leads to far better outcomes. In that mode, the model supports exploration and refinement rather than simply delivering answers.

Treat LLMs as a **feedback loop for thinking**, not a source of answers.  
Iterate, evaluate, and steer—don’t delegate judgment.

---

## Golden Rules

### 1. Feed It Good Context

Before you start, gather everything relevant into simple text or markdown files:

- Your notes and rough ideas  
- Key sources and references (copy relevant passages)  
- Any data you're working with  
- The article’s constraints (audience, tone, length, format)

**Why?** The model works with what you give it. Clean, well-organized input produces coherent output.

---

### 2. Divide and Conquer

Never ask:

> “Write me an article about X”

Instead, ask:

> “I want to write an article about X. Help me break this into steps we can tackle one at a time.”

Then work through each step:
- Outline first, review and adjust
- Each section as a separate task
- Refine before moving on

**Why?** Small chunks are easier to verify, easier to steer, and easier to correct.

---

### 3. Never Trust AI Math

The model will confidently produce incorrect calculations.

Instead of letting it calculate, ask:

> “Don’t calculate this yourself. Write a small program or query that computes it so I can verify the result.”

Use code, spreadsheets, or tools you trust to validate any numbers or data analysis.

---

### 4. Trust but Verify

LLMs can hallucinate citations, invent statistics, and state falsehoods confidently. Every factual claim in your final article must trace back to a real source you’ve actually checked.

---

## The Workflow

1. Load context → 
2. Get a plan → 
3. Execute step by step → 
4. Verify each step

And Iterate as needed 


---

## Quick Reference

| Do | Don’t |
|---|---|
| Provide clean, organized inputs | Dump raw, messy notes |
| Ask for a step-by-step plan | Ask for a full article in one go |
| Verify calculations externally | Trust AI math |
| Review each section | Rush to the end |
| Actively steer | Assume it understood |

---

*The goal isn’t to have AI write your article — it’s to have AI help you write a better one, faster, while staying fully accountable for the result.*
