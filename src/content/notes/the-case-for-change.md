---
title: "The Case for Change: Why AI Adoption Is a Human Problem"
description: "Knowing your organisation needs to adopt AI and actually making it happen are two very different problems. The technology is almost never the hard part. Habits are."
section: "notes"
publishedAt: 2026-02-12
---

Knowing your organisation needs to adopt AI and actually making it happen are two very different problems. The technology is almost never the hard part. Habits are.

But if we step back and think about AI adoption as what it really is — innovation — we gain access to decades of hard-won lessons about how new ideas actually take root inside established organisations. Researchers at SRI International, venture capitalists in Silicon Valley, and change leaders across industries have been studying this problem long before large language models existed. What drives people to embrace change? What makes them resist? Why do some initiatives land while others quietly die?

Those lessons turn out to be remarkably applicable to AI — and they form an essential toolkit for anyone trying to drive adoption from within. A companion piece, [The Playbook](/notes/the-playbook-driving-ai-innovation), translates these ideas into practical recipes and step-by-step techniques. This article is about why those tools work.

## Innovation Is Delivery, Not Invention

Start with a distinction that matters more than it seems: the difference between **invention** and **innovation**.

An invention is a clever new idea. Innovation is the successful creation and delivery of new value. A brilliant AI proof-of-concept that never makes it past the demo is an invention. An AI-powered workflow that actually gets deployed, adopted, and measurably improves outcomes is an innovation.

This matters because most organisations are littered with abandoned proofs-of-concept. Someone builds something impressive in a hackathon, everyone applauds, and then nothing happens. The technology was never the problem — the failure to deliver it into actual use was.

Innovation is a **systematised discipline**, not a stroke of genius. The Five Disciplines of Innovation framework, developed at SRI International over decades of world-changing projects — from the computer mouse to Siri — tells us we don't need to reinvent our organisations. We need a disciplined approach to creating value, starting with honesty about what problems we're solving.

## Painkillers, Not Vitamins

In a risk-averse setting, it helps enormously to focus on **painkillers, not vitamins**.

A vitamin is nice to have. "Wouldn't it be cool if our chatbot could answer customer questions?" is a vitamin. A painkiller addresses significant, measurable pain. "Our manual invoice processing takes 40 hours per week with a 15% error rate, and our competitors do it in 4 with 2% errors" is a painkiller.

Getting buy-in for a vitamin in a risk-averse organisation is incredibly hard. The institutional antibodies kill it. It's far more effective to identify problems that already keep people up at night, then demonstrate that AI can help.

As David Ladd at Mayfield Fund puts it: "Make sure your innovation is a painkiller and not just a vitamin." It's one of the most useful filters for choosing where to start.

## The Exponential Economy: Why Standing Still Is the Real Risk

If your organisation is cautious about AI because they see it as risky, consider that the greater risk may be standing still.

We live in what has been called the **Exponential Economy** — those increasingly large segments of the economy where price-performance improves at rapid, compounding rates. This isn't limited to tech companies anymore. Legal services, financial analysis, content creation, software development, customer service — all are being transformed by AI at rates that compound over time.

The nature of exponential change is that we overestimate its impact in the short term and catastrophically underestimate it in the long term. Think of the old fable of rice on a chessboard: one grain on the first square, two on the second, four on the third. By the halfway point, the numbers are staggering. By the end, you'd need more rice than has ever been produced in human history. AI follows a similar trajectory — each capability builds on previous ones, and the rate of improvement itself accelerates.

This means the gap between your organisation and its AI-adopting competitors may not be growing linearly — it could be growing exponentially. Every month of delay isn't just one month lost; it's potentially one month of compounding advantage handed to the competition. As Andy Grove put it: "Only the paranoid survive."

The question isn't "can we afford the risk of adopting AI?" It's "can we afford the risk of not trying?"

## The Human Element

### Achievement, Empowerment, Involvement

When researchers studied what drives people to commit to innovation projects, money rarely topped the list. Three fundamental motivators emerged — what's been called the **Motivation Mantra**:

**Achievement.** People want their work to matter. When you pitch an AI initiative, connect it to meaningful outcomes. Don't say "this chatbot uses a large language model with retrieval-augmented generation." Say "this system will cut our customer response time from 48 hours to 4 hours." Give people a goal worth achieving.

**Empowerment.** People want the freedom to do their jobs without being micromanaged. Define the *what* — the outcomes — and let people figure out the *how*. This is especially important with AI tools, where the best results often come from individuals discovering their own creative workflows.

**Involvement.** People need to be included in decisions that affect them. This might be the single most violated principle in failed change initiatives. When people are excluded, they don't just resist — they quietly disengage. Not maliciously, but through the gradual withdrawal of enthusiasm that kills momentum. The people closest to the work know things about it that no one else does. Their input isn't a nice-to-have — it's essential.

### The Trust Commandments

You can have the best AI strategy in the world, but if your team doesn't trust you — or each other — it won't go far. Trust is the foundation on which everything else is built.

**Respect.** When Bob Galvin, former CEO of Motorola, was asked what he focused on leading high-performing teams, he answered simply: "I believe respect for others is the most important value." Respect means treating colleagues' concerns about AI as legitimate rather than dismissing them. When someone says "I'm worried this will make my job irrelevant," their fear contains information you need.

**Integrity.** Say what you mean and follow through. If you tell the team that AI is meant to augment their work, not replace them, that had better be true. People detect the slightest variance between your words and your actions, and any discrepancy will be magnified enormously.

**Generosity of Spirit.** Share credit liberally. When the AI project succeeds, make sure the contributors are recognised. As one experienced innovation leader put it: "An attractive feature of credit is that there is an infinite amount that can be given away."

### Identity: The Real Barrier

Here's something worth appreciating: the biggest barrier to AI adoption often isn't technical skill. It's **identity**.

When you ask a senior professional to start using AI, you're implicitly asking them to change who they are. The lawyer who prides herself on exhaustive case research is being told to let a machine do the first pass. The developer who spent years mastering debugging watches an AI solve problems in seconds. The analyst who built a career on processing complex data sees AI do it faster.

This is terrifying. It triggers what innovation researchers call the need to **"vault the void"** — to cross the psychological gap between an old professional identity and a new one.

The secret is deceptively simple: **show people how their current strengths apply to the new vision**. That lawyer's deep understanding of precedent doesn't become less valuable — it becomes the critical skill for evaluating AI output. The developer's expertise is what lets them recognise when AI-generated code is subtly wrong. The analyst's domain knowledge turns raw AI analysis into actionable insight.

Consider a musician who insists on only performing with instruments he can physically play. "I want to be authentic," he explains. The commitment is admirable. But from the audience's perspective, what matters is the emotional connection, not the production method. The same principle applies professionally: what matters is the quality of the outcome, not whether it was achieved entirely by hand.

Great teachers understand this intuitively. They leverage what students are already good at to help them learn something new. There's a similar role for anyone championing AI adoption — finding the bridge between what people already do well and what AI enables.

## The DNA of Change

Change only happens when three building blocks are in place:

A **Desire** — a genuine recognition that the current situation isn't sustainable.

A **New Vision** — a credible picture of something better.

An **Action Plan** — practical steps to get there.

If any single element is missing, change stalls. And you can hear it in people's language. "I don't see the need" means Desire is missing. "What are we changing *to*?" means Vision is missing. "How do we get there?" means the Action Plan is missing. Listen for these signals — they tell you exactly where you are and what needs to happen next.

Think about learning to ski. You're falling on every turn, sitting in the snow — that's Desire. You see your friend carving turns effortlessly — that's the Vision. An instructor says "edge your skis, shift your weight, face down the hill" — that's the Action Plan. Within days, you're skiing slopes you once looked at longingly.

## FUD Is a Gift

When you start driving AI adoption, you will encounter **Fear, Uncertainty, and Doubt**. It's as certain as gravity.

"I'm too busy." "This won't work here." "We tried something similar before." "This isn't fair to the people whose jobs will change."

Your instinct may be to counter their objections with data and logic. Resist. Instead, treat FUD as a **gift** — because it tells you exactly what needs fixing.

Behind every FUD complaint is a legitimate concern. "I'm too busy" really means "I'm out of energy — show me this is worth it." "This won't work" means "I can't visualise it — help me see it." "I'll fight you on this" means "I feel excluded — involve me."

The skill of **reframing** — hearing the constructive need behind the surface complaint — is perhaps one of the most valuable capabilities a change champion can develop. Embedded within each expression of FUD is often a kernel of hope the speaker may not even recognise. The challenge is to unwrap it and address it.

The most effective navigators of resistance never respond to aggression with anger. They say things like "Let me repeat what you've said to make sure I understand" or "That's an interesting point — my experience suggests a different approach." Because their responses are both respectful and reasonable, they win people over.

## No Champion, No Project

If an AI initiative is going to succeed, someone has to take **genuine ownership**. This is the Innovation Champion, and the role goes beyond project management.

There's a principle that resonates deeply: **No champion, no project, no exception.**

The champion proactively identifies with the people affected by the change. They work through funding, bureaucratic, political, human, and technical challenges. They don't wait for problems — they anticipate them, build alliances, refine the value proposition, and keep the team aligned when things get difficult.

Crucially, the champion models the behaviours they want to see. If you want your team to embrace AI, be visibly using it yourself. People will watch closely for any sign of hesitancy and interpret it as evidence that this initiative, like so many before it, will fade away.

## What Comes Next

This article has laid out the conceptual foundation: the urgency of the exponential economy, the human psychology of change, and the principles that separate initiatives that land from those that don't.

But principles without practice stay abstract. The companion piece — *[The Playbook: Driving AI Innovation from Within](/notes/the-playbook-driving-ai-innovation)* — translates these ideas into concrete tools: NABC value propositions, FUD translation tables, nemawashi techniques, and step-by-step recipes for getting from idea to deployment.

The wall is built brick by brick. Understanding *why* the bricks matter is the first step. Knowing *how* to lay them is the second.

---

*The innovation frameworks discussed in this article draw on principles from SRI International's Five Disciplines of Innovation, particularly the work of Curtis R. Carlson and William W. Wilmot. Interpretations and applications are my own.*